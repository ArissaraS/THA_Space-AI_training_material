{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2efda990-915a-4f44-87a2-656814964f66",
   "metadata": {},
   "source": [
    "# This notebook was created to pre-process the spot images for futher fine tuning the prithvi model \n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "* The learner who want to pre-process the spot images for futher fine tuning the prithvi model to classify land use\n",
    "\n",
    "## Tasks\n",
    "\n",
    "1. Importing Necessary Libraries\n",
    "2. Calculates vegetation and water indices (NDVI and NDWI) from a raster image\n",
    "3. Processes a set of multiband images and stacks all the bands into a single raster file\n",
    "4. Reproject and resample a land use raster image (landuse_image) to a specified resolution and spatial reference system (SRS)\n",
    "5. Clip to reference extent\n",
    "6. Creating patches from raster datasets\n",
    "7.  Organizes the outputs for the specified region\n",
    "\n",
    "\n",
    "\n",
    "## prithvi model\n",
    "\n",
    "Prithvi-EO-1.0 is a first-of-its-kind temporal Vision transformer pre-trained by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS) data. The model adopts a self-supervised encoder developed with a ViT architecture and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function. The model includes spatial attention across multiple patches and also temporal attention for each patch.\n",
    "\n",
    "The Prithvi model is a pre-trained deep learning model designed specifically for geospatial and remote sensing applications. It is tailored to work with satellite imagery and supports tasks such as land use and land cover (LULC) classification, segmentation, and other image analysis objectives\n",
    "\n",
    "\n",
    "**How the Prithvi Model Works in a Land Use Classification Workflow**\n",
    "\n",
    "* Input Data: Multi-band satellite imagery (e.g., SPOT, Sentinel-2) is pre-processed (clipping, upscaling, stacking, patching).\n",
    "* Model Fine-Tuning: The pre-trained Prithvi model is fine-tuned on the target dataset using labeled training samples for the specific classification task.\n",
    "* Prediction: The fine-tuned model predicts land use classes for the input imagery, generating detailed maps.\n",
    "* Output: Classified land use maps that can be visualized and analyzed for decision-making.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c01ae-1cce-44ab-b58a-3fda3bae858f",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries\n",
    "\n",
    "#### rasterio:\n",
    "- A Python library for reading and writing geospatial raster data.\n",
    "- It provides tools for working with raster datasets in formats like GeoTIFF.\n",
    "- Rasterio enables georeferencing and allows easy access to metadata and bands of raster files.\n",
    "\n",
    "#### numpy:\n",
    "- A library for numerical computing in Python.\n",
    "- Often used for array manipulation, mathematical operations, and working with raster data as numerical arrays.\n",
    "\n",
    "#### glob:\n",
    "- A Python module for finding files and directories that match a specified pattern.\n",
    "- Useful for searching for raster files in a directory.\n",
    "#### os:\n",
    "- A module that provides functions for interacting with the operating system.\n",
    "- Used for file path manipulations, creating directories, or listing files.\n",
    "- Create output directories for storing processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313eca4b-9032-4079-b9e8-6049a9249807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c037b2-dde1-475e-bace-859ab022d19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.24.3)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/conda/lib/python3.10/site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pyogrio>=0.7.2->geopandas) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5ce08c-efe0-4b87-afe2-14276499662a",
   "metadata": {},
   "source": [
    "## Thing need to use the preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3242316-3005-4869-9e7c-ce4f80be8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name='khon-kaen' # Place or experiment name we are working\n",
    "#output_folder=f'./outputs_spotb_22/{place_name}/' # Keep it as it is\n",
    "output_folder= \"/home/jovyan/shared/PCN/Prithvi/notebook/outputs_spotb_22\"\n",
    "spot_images_folder_path = \"/home/jovyan/shared/2025_THA_LDD_training/SPOT/B/SPOT\" # Folder path which contains all three spot image from different time\n",
    "landuse_path='/home/jovyan/shared/PCN/Prithvi/01_preprocessing/kon-kaen_lu_raster/gt_LU2022B.tif' # Rasterized landuse path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e94c5-885c-4755-8654-b2fe6eaa1bb2",
   "metadata": {},
   "source": [
    "## Calculate indicies and stack all three images with calculated indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93ab0faa-6313-4222-82a1-26ea0a8465a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indices(image_path):\n",
    "    with rasterio.open(image_path) as src:\n",
    "        red = src.read(1).astype(float)\n",
    "        green = src.read(2).astype(float)\n",
    "        blue = src.read(3).astype(float)\n",
    "        nir = src.read(4).astype(float)\n",
    "\n",
    "        meta = src.meta\n",
    "    epsilon = 1e-10\n",
    "    ndvi = (nir - red) / (nir + red + epsilon)\n",
    "    ndwi = (green - nir) / (green + nir + epsilon)\n",
    "    \n",
    "    return ndvi, ndwi, meta\n",
    "\n",
    "def process_and_stack_images(folder_path, output_path):\n",
    "    # Get all multiband images\n",
    "    image_files = sorted(glob.glob(os.path.join(folder_path, \"*.tif\")))\n",
    "    \n",
    "    if len(image_files) != 3:\n",
    "        raise ValueError(f\"Expected 3 images, found {len(image_files)}\")\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images: {image_files}\")\n",
    "    all_bands = []\n",
    "    for image_path in image_files:\n",
    "        print(f\"Processing {image_path}...\")\n",
    "        with rasterio.open(image_path) as src:\n",
    "            bands = [src.read(i) for i in range(1, 5)]  \n",
    "            meta = src.meta\n",
    "        ndvi, ndwi, _ = calculate_indices(image_path)\n",
    "        all_bands.extend(bands + [ndvi, ndwi])\n",
    "    \n",
    "    meta.update({\n",
    "        'count': len(all_bands),  #18 bands total(6 bands Ã— 3 images)\n",
    "        'dtype': 'float32'\n",
    "    })\n",
    "    os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)\n",
    "    print(f\"Saving stacked image to {output_path}...\")\n",
    "    with rasterio.open(output_path, 'w', **meta) as dst:\n",
    "        for idx, band in enumerate(all_bands, start=1):\n",
    "            dst.write(band.astype(np.float32), idx)\n",
    "    print(\"Done with calculating and stacking all bands!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da3c5e-e210-4f72-9410-44cf7b2a5c46",
   "metadata": {},
   "source": [
    "## The script defines variables and uses the process_and_stack_images function to process raster images and create a stacked output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cec5989-1415-4a00-855f-43b191915231",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It may take upto 5 min to calculate indices and stack image\n",
    "stacked_spot_image =os.path.join(output_folder,\"stack/18_band_spot_b.tif\" ) # give file name to stack image\n",
    "#stacked_spot_image= \"/home/jovyan/shared/PCN/Prithvi/notebook/outputs_spotb_22/khon-kaen/stack/18_band_spot_b.tif\"\n",
    "process_and_stack_images(spot_images_folder_path, stacked_spot_image )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd799fb-56a3-4d9e-a275-a4ce61436343",
   "metadata": {},
   "source": [
    "## The code below will first clip the landuse image with the extent of the spot image and then it will create patch of 224*224 for both images\n",
    "\n",
    "It is separated into three main functions and a main workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c1fd7-c0a6-4450-9eb6-6b29c75c5943",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e045339-9e56-4e39-a9e3-38841839a716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b8737-b855-4e09-9b21-7b60f8297ff8",
   "metadata": {},
   "source": [
    "### Extract the bounding box (extent) from the reference raster file and Clip the source_path raster to match the reference extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ced05-9faf-4c45-a546-6fc527634aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_to_reference_extent(source_path, reference_path, output_path):\n",
    "    print(f\"Clipping {os.path.basename(source_path)} to reference extent...\")\n",
    "    # Get reference image extent\n",
    "    with rio.open(reference_path) as ref:\n",
    "        ref_bounds = ref.bounds\n",
    "        ref_bbox = box(ref_bounds.left, ref_bounds.bottom, ref_bounds.right, ref_bounds.top)\n",
    "        ref_gdf = gpd.GeoDataFrame({'geometry': [ref_bbox]}, crs=ref.crs)\n",
    "    \n",
    "    # Clip source to reference extent\n",
    "    with rio.open(source_path) as src:\n",
    "        ref_gdf = ref_gdf.to_crs(src.crs)\n",
    "        out_image, out_transform = mask(src, ref_gdf.geometry, crop=True)\n",
    "        \n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform\n",
    "        })\n",
    "        \n",
    "        with rio.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "    print(\"Clipping completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f925a5-696f-4018-a56e-b289c549deb3",
   "metadata": {},
   "source": [
    "## Create training patches of size 224*224 for both spot image and landuse image\n",
    "\n",
    " **Calculate the number of patches required along the width (x) and height (y) of the raster.**\n",
    "- Divide the raster dimensions by the patch size and round up to ensure full coverage.\n",
    "- Calculate the total number of patches (total_patches).\n",
    "\n",
    "**Fine-Tuning Pre-trained Models**:\n",
    "\n",
    "Using 224x224 patches ensures that the satellite image patches can directly serve as input for models like the Prithvi model or other pre-trained architectures without additional resizing, preserving details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d16c30-acb0-48e5-aad7-afa1a4897171",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_patches(image_path, output_dir, patch_size=224):\n",
    "    with rio.open(image_path) as src:\n",
    "        # Calculate number of patches\n",
    "        num_patches_x = int(np.ceil(src.width / patch_size))\n",
    "        num_patches_y = int(np.ceil(src.height / patch_size))\n",
    "        total_patches = num_patches_y * num_patches_x\n",
    "        \n",
    "        print(f\"Creating {total_patches} patches for {os.path.basename(image_path)}...\")\n",
    "        \n",
    "        # Create progress bar\n",
    "        pbar = tqdm(total=total_patches, desc=\"Creating patches\")\n",
    "        \n",
    "        for y in range(num_patches_y):\n",
    "            for x in range(num_patches_x):\n",
    "                # Define window for current patch\n",
    "                window = Window(x * patch_size, y * patch_size, patch_size, patch_size)\n",
    "                transform = rio.windows.transform(window, src.transform)\n",
    "                patch = src.read(window=window)\n",
    "                profile = src.profile.copy()\n",
    "                profile.update({\n",
    "                    'height': patch.shape[1],\n",
    "                    'width': patch.shape[2],\n",
    "                    'transform': transform\n",
    "                })\n",
    "                \n",
    "                # Use same naming pattern for both landuse and spot patches\n",
    "                patch_name = f\"patch_{x:03d}_{y:03d}.tif\"\n",
    "                output_path = os.path.join(output_dir, patch_name)\n",
    "                \n",
    "                with rio.open(output_path, 'w', **profile) as dest:\n",
    "                    dest.write(patch)\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        pbar.close()\n",
    "    print(f\"Patch creation completed for {os.path.basename(image_path)}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e66506d-833d-4095-a6b6-eeb97aee627f",
   "metadata": {},
   "source": [
    "### Process images\n",
    "\n",
    "- Create directories for storing land use and SPOT image patches.\n",
    "- Align the land use raster to the extent of the SPOT imagery using the clip_to_reference_extent function.\n",
    "- Create patches for both the clipped land use raster and SPOT imagery using the create_patches function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88e657-25b6-4be4-8287-b2a4df0403ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(landuse_path, spot_path, output_base_dir):\n",
    "    print(\"Starting image processing...\")\n",
    "    \n",
    "    # Create output directories\n",
    "    landuse_patches_dir = os.path.join(output_base_dir, 'landuse_patches_big_extent')\n",
    "    spot_patches_dir = os.path.join(output_base_dir, 'spot_patches_big_extent')\n",
    "    os.makedirs(landuse_patches_dir, exist_ok=True)\n",
    "    os.makedirs(spot_patches_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. First clip landuse to spot extent\n",
    "    clipped_landuse_path = os.path.join(output_base_dir, 'clipped_landuse_big_extent.tif')\n",
    "    clip_to_reference_extent(landuse_path, spot_path, clipped_landuse_path)\n",
    "    \n",
    "    # 2. Create patches for both images\n",
    "    create_patches(clipped_landuse_path, landuse_patches_dir)\n",
    "    create_patches(spot_path, spot_patches_dir)\n",
    "    \n",
    "    print(\"Image processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6939ad8-f6eb-4c4a-a361-90a1f4947d0a",
   "metadata": {},
   "source": [
    "This script processes land use and SPOT imagery for the region specified by the place_name variable (khon-kaen in this case). It aligns the land use raster to the SPOT imagery's extent and resolution, and then divides both datasets into smaller patches for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1ab7b17-4ca2-4df8-af5a-6f98d9bb1ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting image processing...\n",
      "Clipping gt_LU2022B.tif to reference extent...\n",
      "Clipping completed!\n",
      "Creating 2516 patches for clipped_landuse_big_extent.tif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2516/2516 [08:41<00:00,  4.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch creation completed for clipped_landuse_big_extent.tif!\n",
      "Creating 2070 patches for 18_band_spot_b.tif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating patches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2070/2070 [23:46<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch creation completed for 18_band_spot_b.tif!\n",
      "Image processing completed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process_images(\n",
    "    landuse_path=landuse_path, # File path of the landuse image\n",
    "    spot_path=stacked_spot_image,\n",
    "    output_base_dir=output_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bddcc4-fd85-4d3d-9dff-7ea8f0638123",
   "metadata": {},
   "source": [
    "## Filter the patches created above as some of them might not be clipped to 224*224 size\n",
    "\n",
    "Ensure all images in a folder are of the required size (224x224 pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8045a4e3-cea6-4e4d-a3b0-36db63a4aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def filter_patch_images(image_folder):\n",
    "    desired_width, desired_height = 224, 224\n",
    "    deleted_files = []\n",
    "    image_files = [f for f in os.listdir(image_folder) if f.endswith('.tif')]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing Images\", unit=\"image\"):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        try:\n",
    "            with rasterio.open(image_path) as src:\n",
    "                width, height = src.width, src.height\n",
    "                if (width, height) != (desired_width, desired_height):\n",
    "                    os.remove(image_path)\n",
    "                    deleted_files.append(image_file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n",
    "    \n",
    "    print(\"\\nSummary:\")\n",
    "    print(f\"Total images processed: {len(image_files)}\")\n",
    "    print(f\"Images deleted: {len(deleted_files)}\")\n",
    "    if deleted_files:\n",
    "        print(\"Deleted files:\")\n",
    "        for file in deleted_files:\n",
    "            print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f07de6-c6d9-4e51-ba7c-aa42ce0e0149",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2070/2070 [00:57<00:00, 35.80image/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Total images processed: 2070\n",
      "Images deleted: 98\n",
      "Deleted files:\n",
      "- patch_068_007.tif\n",
      "- patch_068_021.tif\n",
      "- patch_009_029.tif\n",
      "- patch_024_029.tif\n",
      "- patch_029_029.tif\n",
      "- patch_050_029.tif\n",
      "- patch_056_029.tif\n",
      "- patch_068_027.tif\n",
      "- patch_003_029.tif\n",
      "- patch_013_029.tif\n",
      "- patch_019_029.tif\n",
      "- patch_039_029.tif\n",
      "- patch_047_029.tif\n",
      "- patch_060_029.tif\n",
      "- patch_064_029.tif\n",
      "- patch_068_000.tif\n",
      "- patch_017_029.tif\n",
      "- patch_031_029.tif\n",
      "- patch_068_028.tif\n",
      "- patch_016_029.tif\n",
      "- patch_033_029.tif\n",
      "- patch_063_029.tif\n",
      "- patch_068_002.tif\n",
      "- patch_018_029.tif\n",
      "- patch_045_029.tif\n",
      "- patch_054_029.tif\n",
      "- patch_068_004.tif\n",
      "- patch_068_013.tif\n",
      "- patch_022_029.tif\n",
      "- patch_028_029.tif\n",
      "- patch_055_029.tif\n",
      "- patch_059_029.tif\n",
      "- patch_066_029.tif\n",
      "- patch_067_029.tif\n",
      "- patch_002_029.tif\n",
      "- patch_011_029.tif\n",
      "- patch_027_029.tif\n",
      "- patch_038_029.tif\n",
      "- patch_040_029.tif\n",
      "- patch_068_003.tif\n",
      "- patch_068_014.tif\n",
      "- patch_068_016.tif\n",
      "- patch_068_018.tif\n",
      "- patch_007_029.tif\n",
      "- patch_043_029.tif\n",
      "- patch_052_029.tif\n",
      "- patch_061_029.tif\n",
      "- patch_032_029.tif\n",
      "- patch_068_029.tif\n",
      "- patch_068_009.tif\n",
      "- patch_068_008.tif\n",
      "- patch_068_006.tif\n",
      "- patch_068_026.tif\n",
      "- patch_000_029.tif\n",
      "- patch_014_029.tif\n",
      "- patch_025_029.tif\n",
      "- patch_051_029.tif\n",
      "- patch_053_029.tif\n",
      "- patch_068_011.tif\n",
      "- patch_068_017.tif\n",
      "- patch_068_019.tif\n",
      "- patch_068_023.tif\n",
      "- patch_021_029.tif\n",
      "- patch_034_029.tif\n",
      "- patch_068_001.tif\n",
      "- patch_068_012.tif\n",
      "- patch_068_024.tif\n",
      "- patch_020_029.tif\n",
      "- patch_068_010.tif\n",
      "- patch_068_022.tif\n",
      "- patch_008_029.tif\n",
      "- patch_010_029.tif\n",
      "- patch_057_029.tif\n",
      "- patch_001_029.tif\n",
      "- patch_023_029.tif\n",
      "- patch_036_029.tif\n",
      "- patch_049_029.tif\n",
      "- patch_012_029.tif\n",
      "- patch_068_020.tif\n",
      "- patch_068_025.tif\n",
      "- patch_005_029.tif\n",
      "- patch_041_029.tif\n",
      "- patch_042_029.tif\n",
      "- patch_044_029.tif\n",
      "- patch_048_029.tif\n",
      "- patch_065_029.tif\n",
      "- patch_068_005.tif\n",
      "- patch_030_029.tif\n",
      "- patch_004_029.tif\n",
      "- patch_006_029.tif\n",
      "- patch_026_029.tif\n",
      "- patch_037_029.tif\n",
      "- patch_058_029.tif\n",
      "- patch_068_015.tif\n",
      "- patch_015_029.tif\n",
      "- patch_035_029.tif\n",
      "- patch_046_029.tif\n",
      "- patch_062_029.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2516/2516 [00:56<00:00, 44.78image/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary:\n",
      "Total images processed: 2516\n",
      "Images deleted: 107\n",
      "Deleted files:\n",
      "- patch_073_017.tif\n",
      "- patch_073_021.tif\n",
      "- patch_073_032.tif\n",
      "- patch_012_033.tif\n",
      "- patch_028_033.tif\n",
      "- patch_030_033.tif\n",
      "- patch_042_033.tif\n",
      "- patch_060_033.tif\n",
      "- patch_031_033.tif\n",
      "- patch_071_033.tif\n",
      "- patch_038_033.tif\n",
      "- patch_073_008.tif\n",
      "- patch_073_022.tif\n",
      "- patch_073_031.tif\n",
      "- patch_041_033.tif\n",
      "- patch_043_033.tif\n",
      "- patch_045_033.tif\n",
      "- patch_062_033.tif\n",
      "- patch_051_033.tif\n",
      "- patch_073_018.tif\n",
      "- patch_008_033.tif\n",
      "- patch_017_033.tif\n",
      "- patch_033_033.tif\n",
      "- patch_055_033.tif\n",
      "- patch_061_033.tif\n",
      "- patch_073_027.tif\n",
      "- patch_029_033.tif\n",
      "- patch_037_033.tif\n",
      "- patch_073_004.tif\n",
      "- patch_073_003.tif\n",
      "- patch_073_007.tif\n",
      "- patch_073_002.tif\n",
      "- patch_023_033.tif\n",
      "- patch_032_033.tif\n",
      "- patch_036_033.tif\n",
      "- patch_070_033.tif\n",
      "- patch_073_000.tif\n",
      "- patch_002_033.tif\n",
      "- patch_010_033.tif\n",
      "- patch_035_033.tif\n",
      "- patch_034_033.tif\n",
      "- patch_069_033.tif\n",
      "- patch_006_033.tif\n",
      "- patch_013_033.tif\n",
      "- patch_018_033.tif\n",
      "- patch_040_033.tif\n",
      "- patch_054_033.tif\n",
      "- patch_073_012.tif\n",
      "- patch_073_006.tif\n",
      "- patch_073_024.tif\n",
      "- patch_073_030.tif\n",
      "- patch_063_033.tif\n",
      "- patch_064_033.tif\n",
      "- patch_073_028.tif\n",
      "- patch_025_033.tif\n",
      "- patch_073_015.tif\n",
      "- patch_027_033.tif\n",
      "- patch_046_033.tif\n",
      "- patch_073_009.tif\n",
      "- patch_073_029.tif\n",
      "- patch_011_033.tif\n",
      "- patch_014_033.tif\n",
      "- patch_073_013.tif\n",
      "- patch_026_033.tif\n",
      "- patch_073_010.tif\n",
      "- patch_073_023.tif\n",
      "- patch_052_033.tif\n",
      "- patch_073_016.tif\n",
      "- patch_016_033.tif\n",
      "- patch_022_033.tif\n",
      "- patch_050_033.tif\n",
      "- patch_072_033.tif\n",
      "- patch_073_033.tif\n",
      "- patch_073_025.tif\n",
      "- patch_073_014.tif\n",
      "- patch_067_033.tif\n",
      "- patch_073_005.tif\n",
      "- patch_056_033.tif\n",
      "- patch_073_020.tif\n",
      "- patch_003_033.tif\n",
      "- patch_005_033.tif\n",
      "- patch_024_033.tif\n",
      "- patch_019_033.tif\n",
      "- patch_044_033.tif\n",
      "- patch_053_033.tif\n",
      "- patch_058_033.tif\n",
      "- patch_066_033.tif\n",
      "- patch_007_033.tif\n",
      "- patch_057_033.tif\n",
      "- patch_073_026.tif\n",
      "- patch_004_033.tif\n",
      "- patch_039_033.tif\n",
      "- patch_065_033.tif\n",
      "- patch_073_001.tif\n",
      "- patch_009_033.tif\n",
      "- patch_049_033.tif\n",
      "- patch_068_033.tif\n",
      "- patch_073_019.tif\n",
      "- patch_000_033.tif\n",
      "- patch_001_033.tif\n",
      "- patch_015_033.tif\n",
      "- patch_020_033.tif\n",
      "- patch_021_033.tif\n",
      "- patch_073_011.tif\n",
      "- patch_048_033.tif\n",
      "- patch_047_033.tif\n",
      "- patch_059_033.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "landuse_patch_folder = os.path.join(output_folder,'landuse_patches_big_extent')\n",
    "spot_patch_folder = os.path.join(output_folder,'spot_patches_big_extent')\n",
    "filter_patch_images(spot_patch_folder)\n",
    "filter_patch_images(landuse_patch_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3747ac7f-ab20-49a3-a68c-22069acc5fb0",
   "metadata": {},
   "source": [
    "## Split the patches into train, test, and validation set\n",
    "\n",
    "This process is essential for training machine learning models, where datasets are divided into different subsets for training, validating, and evaluating the model's performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5ab646b-05aa-463b-8bc9-4eaead47c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def create_train_val_test_splits(\n",
    "    image_dir, \n",
    "    mask_dir, \n",
    "    output_dir,\n",
    "    train_ratio=0.70,  # 70% of the data will be used for training.\n",
    "    val_ratio=0.10,    # 10% of the data will be used for validation.\n",
    "    test_ratio=0.20,   # 20% of the data will be used for testing.\n",
    "    random_seed=42\n",
    "):\n",
    "\n",
    "    # Set random seed\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    splits = ['train', 'val', 'test']\n",
    "    for split in splits:\n",
    "        for subdir in ['images', 'masks']:\n",
    "            os.makedirs(os.path.join(output_dir, split, subdir), exist_ok=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith('.tif')]\n",
    "    \n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    total_size = len(image_files)\n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "\n",
    "    train_files = image_files[:train_size]\n",
    "    val_files = image_files[train_size:train_size + val_size]\n",
    "    test_files = image_files[train_size + val_size:]\n",
    "    \n",
    "    def copy_files(file_list, split_name):\n",
    "        print(f\"\\nCopying {split_name} files...\")\n",
    "        for filename in file_list:\n",
    "            src_image = os.path.join(image_dir, filename)\n",
    "            dst_image = os.path.join(output_dir, split_name, 'images', filename)\n",
    "            shutil.copy2(src_image, dst_image)\n",
    "            src_mask = os.path.join(mask_dir, filename)\n",
    "            dst_mask = os.path.join(output_dir, split_name, 'masks', filename)\n",
    "            shutil.copy2(src_mask, dst_mask)\n",
    "    \n",
    "    split_files = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    for split_name, files in split_files.items():\n",
    "        copy_files(files, split_name)\n",
    "        print(f\"{split_name} split: {len(files)} images\")\n",
    "\n",
    "    return {\n",
    "        'train_size': len(train_files),\n",
    "        'val_size': len(val_files),\n",
    "        'test_size': len(test_files)\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0206e28-a09d-4d2e-91a9-b866cdc0c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying train files...\n",
      "train split: 1380 images\n",
      "\n",
      "Copying val files...\n",
      "val split: 197 images\n",
      "\n",
      "Copying test files...\n",
      "test split: 395 images\n",
      "\n",
      "Data split summary:\n",
      "Total images: 1972\n",
      "train_size: 1380 images\n",
      "val_size: 197 images\n",
      "test_size: 395 images\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "final_training_data_folder = os.path.join(output_folder,'final_training_data_big_extent')\n",
    "\n",
    "stats = create_train_val_test_splits(\n",
    "    image_dir=spot_patch_folder,\n",
    "    mask_dir=landuse_patch_folder,\n",
    "    output_dir=final_training_data_folder,\n",
    "    train_ratio=0.70,\n",
    "    val_ratio=0.10,\n",
    "    test_ratio=0.20,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "print(\"\\nData split summary:\")\n",
    "print(f\"Total images: {sum(stats.values())}\")\n",
    "for split_name, size in stats.items():\n",
    "    print(f\"{split_name}: {size} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d8e23c-1699-4ede-b935-c45e964c1800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/shared/megharaj/prithvi_model/code_and_data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ac23c-4124-4b49-b043-b528d88a52f0",
   "metadata": {},
   "source": [
    "## Calculates the mean and standard deviation of pixel values for a dataset of raster images\n",
    "\n",
    "Compute the mean and standard deviation for each channel (e.g., RGB or multispectral bands) across all images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d88739-b226-4781-b632-0658597f8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from glob import glob\n",
    "\n",
    "def calculate_dataset_statistics(image_paths):\n",
    "    means = []\n",
    "    stds = []\n",
    "    \n",
    "    for path in image_paths:\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read()  # Shape: (channels, height, width)\n",
    "            means.append(img.mean(axis=(1, 2)))\n",
    "            stds.append(img.std(axis=(1, 2)))\n",
    "    \n",
    "    channel_means = np.mean(means, axis=0)\n",
    "    channel_stds = np.mean(stds, axis=0)\n",
    "    \n",
    "    return channel_means, channel_stds\n",
    "\n",
    "\n",
    "# image_paths = glob(os.path.join(final_training_data_folder,'train','images','*.tif'))\n",
    "image_paths = glob(os.path.join(final_training_data_folder,'train/images','*.tif'))\n",
    "\n",
    "means, stds = calculate_dataset_statistics(image_paths)\n",
    "means_list = \", \".join(f\"{mean:.5f}\" for mean in means)\n",
    "stds_list = \", \".join(f\"{std:.5f}\" for std in stds)\n",
    "\n",
    "print(\"Channel means:\", means_list)\n",
    "print(\"Channel stds:\", stds_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
